{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "#grab preprocess from pre-trained model\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.utils import load_img,img_to_array\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras_vggface import utils\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = [\n",
    "#         'Angelina_Jolie', 'Brad_Pitt', 'Denzel_Washington', 'Hugh_Jackman', 'Jennifer_Lawrence', 'Johnny_Depp', \n",
    "#         'Kate_Winslet', 'Leonardo_DiCaprio', 'Megan_Fox', 'Natalie_Portman', 'Nicole_Kidman',\n",
    "#         'Robert_Downey_Jr', 'Sandra_Bullock', 'Scarlett_Johansson', 'Tom_Cruise','Tom_Hanks', 'Will_Smith'\n",
    "#         ]\n",
    "\n",
    "names = [\"Anudari\", \"Cebastian\", \"Chris\", \"Michael\"]\n",
    "\n",
    "mask_label = ['with mask', 'without mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg19 (Functional)          (None, 512)               20024384  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,288,066\n",
      "Trainable params: 4,983,298\n",
      "Non-trainable params: 15,304,768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "### MASK/NO MASK ###\n",
    "####################\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "\n",
    "mask_no_mask_model = tf.keras.models.load_model('./MODELS/chris_mask_nomask_model.h5')\n",
    "mask_no_mask_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "### MASK/NO MASK ###\n",
    "####################\n",
    "#load the image\n",
    "image1 = image.load_img(\"../NEW_DATASET/masked/chris/IMG_6344.JPG\", target_size = (224, 224))\n",
    "\n",
    "transformedImage = image.img_to_array(image1)\n",
    "transformedImage = np.expand_dims(transformedImage, axis = 0)\n",
    "transformedImage = preprocess_input(transformedImage)\n",
    "\n",
    "prediction = mask_no_mask_model.predict(transformedImage)\n",
    "print(mask_label[np.argmax(prediction, axis=1)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " global_average_pooling2d_8   (None, 512)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1024)              525312    \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,126,148\n",
      "Trainable params: 22,126,148\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "### UNMASKED FACE ###\n",
    "#####################\n",
    "unmasked_model = tf.keras.models.load_model('./MODELS/new_nomask_model.h5')\n",
    "unmasked_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "### UNMASKED FACE ###\n",
    "#####################\n",
    "#load the image\n",
    "#my_image = load_img('../NEW_DATASET/unmasked/chris/IMG_6245.JPG', target_size=(224, 224))\n",
    "my_image = load_img('S:/ElitePictures/Home/face.jpeg', target_size=(224, 224))\n",
    "\n",
    "\n",
    "#preprocess the image\n",
    "my_image = img_to_array(my_image)\n",
    "my_image = my_image.reshape((1, my_image.shape[0], my_image.shape[1], my_image.shape[2]))\n",
    "my_image = preprocess_input(my_image)\n",
    "\n",
    "#make the prediction\n",
    "prediction = unmasked_model.predict(my_image)\n",
    "print(prediction)\n",
    "print(names[np.argmax(prediction[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv1_1 (Conv2D)            (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " conv1_2 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " conv2_1 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2_2 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv3_1 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv3_2 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv3_3 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " pool3 (MaxPooling2D)        (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv4_1 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " conv4_2 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " conv4_3 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " pool4 (MaxPooling2D)        (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv5_1 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv5_2 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv5_3 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " pool5 (MaxPooling2D)        (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc6 (Dense)                 (None, 512)               12845568  \n",
      "                                                                 \n",
      " fc7 (Dense)                 (None, 512)               262656    \n",
      "                                                                 \n",
      " fc8 (Dense)                 (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,824,964\n",
      "Trainable params: 13,110,276\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "### MASKED FACE ###\n",
    "###################\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "\n",
    "masked_model = tf.keras.models.load_model('./MODELS/new_mask_model.h5')\n",
    "masked_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00 1.6350104e-16]]\n",
      "Anudari\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "### MASKED FACE ###\n",
    "###################\n",
    "#load the image\n",
    "#my_image = load_img('../NEW_DATASET/masked/michael/IMG_6105.JPG', target_size=(224, 224))\n",
    "my_image = load_img('S:/ElitePictures/Home/face/PXL_20221205_061840469.jpg', target_size=(224, 224))\n",
    "\n",
    "\n",
    "#preprocess the image\n",
    "my_image = img_to_array(my_image)\n",
    "my_image = my_image.reshape((1, my_image.shape[0], my_image.shape[1], my_image.shape[2]))\n",
    "my_image = preprocess_input(my_image)\n",
    "\n",
    "#make the prediction\n",
    "prediction = masked_model.predict(my_image)\n",
    "print(prediction)\n",
    "print(names[np.argmax(prediction[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "### TEST ONE IMAGE ###\n",
    "######################\n",
    "#my_image = load_img('../IN_YOUR_FACE_DATASET/MASKED_CELEBRITIES/Megan_Fox/Megan_Fox_006_cloth.jpg', target_size=(224, 224))\n",
    "my_image = load_img('../NEW_DATASET/masked/chris/IMG_6306.JPG', target_size=(224, 224))\n",
    "\n",
    "my_image = img_to_array(my_image)\n",
    "my_image = np.expand_dims(my_image, axis=0)\n",
    "my_image = preprocess_input(my_image)\n",
    "\n",
    "predictionLabel= ''\n",
    "prediction = mask_no_mask_model.predict(my_image)\n",
    "\n",
    "if mask_label[np.argmax(prediction, axis=1)[0]] == 'with mask':\n",
    "    predictionLabel = 'Masked - '\n",
    "    prediction = masked_model.predict(my_image)\n",
    "else:\n",
    "    predictionLabel = 'Unmasked - '\n",
    "    prediction = unmasked_model.predict(my_image)\n",
    "\n",
    "predictionLabel = predictionLabel + names[np.argmax(prediction, axis=1)[0]]\n",
    "\n",
    "\n",
    "print(predictionLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "### TEST MULTIPLE MIXED IMAGES ###\n",
    "##################################\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "test_data_dir = '../NEW_DATASET/mixed/'\n",
    "test_datagen = ImageDataGenerator()\n",
    "Test_data = test_datagen.flow_from_directory(\n",
    "                        test_data_dir,\n",
    "                        batch_size = 1,\n",
    "                        target_size=(224,224),\n",
    "                        shuffle = False) \n",
    "\n",
    "#Predict test images\n",
    "Y_pred = mask_no_mask_model.predict(Test_data) #fixme:: branch to which ever is mask or no mask\n",
    "\n",
    "#Get corresponding predicted label\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "cf = confusion_matrix(Test_data.classes, y_pred)\n",
    "\n",
    "\n",
    "df_cm = pd.DataFrame(cf, index=names, columns=names)\n",
    "\n",
    "sns.heatmap(df_cm, annot= True,fmt=\"d\",cmap=\"YlGnBu\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.title(\"Confusion matrix\\n\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir = '../NEW_DATASET/masked/'\n",
    "test_datagen = ImageDataGenerator(\n",
    "                                 )\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                        test_data_dir,\n",
    "                        target_size=(224,224),\n",
    "                        batch_size=32, \n",
    "                        shuffle = False,\n",
    "                        class_mode='sparse') \n",
    "\n",
    "#Confusion Matrix \n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "#Predict test images\n",
    "Y_pred = masked_model.predict(test_generator)\n",
    "\n",
    "#Get corresponding predicted label\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "cf = confusion_matrix(test_generator.classes, y_pred)\n",
    "\n",
    "df_cm = pd.DataFrame(cf, index=names, columns=names)\n",
    "\n",
    "sns.heatmap(df_cm, annot= True,fmt=\"d\",cmap=\"YlGnBu\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.title(\"Confusion matrix\\n\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD IMAGE\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import face_recognition\n",
    "\n",
    "#frame = load_img('../NEW_DATASET/masked/anudari/IMG_6482.JPG', target_size=(224, 224))\n",
    "#frame = cv2.imread('../NEW_DATASET/masked/michael/IMG_6112.JPG')\n",
    "# frame = face_recognition.load_image_file('../NEW_DATASET/masked/anudari/IMG_6515.JPG')\n",
    "# frame = cv2.resize(frame, (1164,896))\n",
    "\n",
    "#image_path = ('../NEW_DATASET/unmasked/michael/IMG_5939.JPG')\n",
    "image_path = ('S:/ElitePictures/Home/face/PXL_20221205_061450711.MP.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DETECT FACE LOCATION USING DNN\n",
    "dnn_label = ''\n",
    "dnn_boxColor = (0,0,0)\n",
    "\n",
    "network = cv2.dnn.readNetFromCaffe(\"./MODELS/deploy.prototxt\", \"./MODELS/res10_300x300_ssd_iter_140000_fp16.caffemodel\")\n",
    "\n",
    "dnn_image = cv2.imread(image_path)\n",
    "dnn_image = cv2.resize(dnn_image, (582,448))\n",
    "\n",
    "(height, width) = dnn_image.shape[:2]\n",
    "blob = cv2.dnn.blobFromImage(dnn_image, scalefactor=1.0, size=(300, 300), mean=(104.0, 117.0, 123.0))\n",
    "network.setInput(blob)\n",
    "detections = network.forward()\n",
    "\n",
    "for i in range(0, detections.shape[2]):\n",
    "    confidence = detections[0, 0, i, 2]\n",
    "    if confidence > 0.5:\n",
    "        box = detections[0, 0, i, 3:7] * np.array([width, height, width, height])\n",
    "        left = int(box[0])\n",
    "        top = int(box[1])\n",
    "        right = int(box[2])\n",
    "        bottom = int(box[3])\n",
    "\n",
    "###\n",
    "new_frame = cv2.resize(dnn_image, (224,224))\n",
    "x = image.img_to_array(new_frame)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "dnn_prediction = ''\n",
    "\n",
    "mask_prediction = mask_no_mask_model.predict(x)\n",
    "\n",
    "if mask_label[np.argmax(mask_prediction, axis=1)[0]] == 'with mask':\n",
    "    dnn_label = 'Masked - '\n",
    "    dnn_prediction = masked_model.predict(x)\n",
    "    dnn_boxColor = (255,0,0)\n",
    "else:\n",
    "    dnn_label = 'Unmasked - '\n",
    "    dnn_prediction = unmasked_model.predict(x)\n",
    "    dnn_boxColor = (0,0,255)\n",
    "\n",
    "dnn_label = dnn_label + names[np.argmax(dnn_prediction, axis=1)[0]]\n",
    "###\n",
    "\n",
    "cv2.rectangle(dnn_image, (left - 10, top - 50), (right + 10, bottom + 50), dnn_boxColor, 2)\n",
    "cv2.rectangle(dnn_image, (left - 11, top - 49), (right + 11, top -24), dnn_boxColor, cv2.FILLED)\n",
    "font = cv2.FONT_HERSHEY_DUPLEX\n",
    "cv2.putText(dnn_image, dnn_label, (left - 6, top - 36), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "cv2.imshow(\"DNN\", dnn_image)\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DETECT FACE LOCATION USING HAAR CASCADE\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "#eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "haar_label = ''\n",
    "boxColor = (0,0,0)\n",
    "\n",
    "haar_image = cv2.imread(image_path)\n",
    "haar_image = cv2.resize(haar_image, (582, 448))\n",
    "faces = face_cascade.detectMultiScale(haar_image)\n",
    "#to draw faces on image\n",
    "for result in faces:\n",
    "    x_point, y_point, w, h = result\n",
    "    x2_point, y2_point = x_point + w, y_point + h\n",
    "    \n",
    "    ###\n",
    "    new_frame = cv2.resize(haar_image, (224,224))\n",
    "    x = image.img_to_array(new_frame)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    mtcnn_prediction = mask_no_mask_model.predict(x)\n",
    "\n",
    "    if mask_label[np.argmax(mtcnn_prediction, axis=1)[0]] == 'with mask':\n",
    "        haar_label = 'Masked - '\n",
    "        mtcnn_prediction = masked_model.predict(x)\n",
    "        boxColor = (255,0,0)\n",
    "    else:\n",
    "        haar_label = 'Unmasked - '\n",
    "        mtcnn_prediction = unmasked_model.predict(x)\n",
    "        boxColor = (0,0,255)\n",
    "\n",
    "    haar_label = haar_label + names[np.argmax(mtcnn_prediction, axis=1)[0]]\n",
    "    ###\n",
    "\n",
    "    cv2.rectangle(haar_image, (x_point - 10, y_point - 50), (x2_point + 10, y2_point + 50), boxColor, 2)\n",
    "    cv2.rectangle(haar_image, (x_point - 11, y_point - 49), (x2_point + 11, y_point - 24), boxColor, cv2.FILLED)\n",
    "    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "    cv2.putText(haar_image, haar_label, (x_point - 6, y_point - 36), font, 0.5, (255, 255, 255), 1)\n",
    "cv2.imshow('Haar Cascade', haar_image)\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DETECT FACE LOCATION USING MTCNN\n",
    "mtcnn_image = face_recognition.load_image_file(image_path)\n",
    "mtcnn_image = cv2.resize(mtcnn_image, (582,448))\n",
    "mtcnn_label=''\n",
    "mtcnn_boxColor = (0,0,0)\n",
    "\n",
    "detector = MTCNN()\n",
    "location = detector.detect_faces(mtcnn_image)\n",
    "for face in location:\n",
    "    x_point, y_point, width, height = face['box']\n",
    "    x2_point, y2_point = x_point + width, y_point + height\n",
    "\n",
    "    ###\n",
    "    new_frame = cv2.resize(mtcnn_image, (224,224))\n",
    "    x = image.img_to_array(new_frame)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    mtcnn_prediction = mask_no_mask_model.predict(x)\n",
    "\n",
    "    if mask_label[np.argmax(mtcnn_prediction, axis=1)[0]] == 'with mask':\n",
    "        mtcnn_label = 'Masked - '\n",
    "        mtcnn_prediction = masked_model.predict(x)\n",
    "        mtcnn_boxColor = (255,0,0)\n",
    "    else:\n",
    "        mtcnn_label = 'Unmasked - '\n",
    "        mtcnn_prediction = unmasked_model.predict(x)\n",
    "        mtcnn_boxColor = (0,0,255)\n",
    "\n",
    "    mtcnn_label = mtcnn_label + names[np.argmax(mtcnn_prediction, axis=1)[0]]\n",
    "    ###\n",
    "    cv2.rectangle(mtcnn_image, (x_point - 10, y_point - 50), (x2_point + 10, y2_point + 50), mtcnn_boxColor, 2)\n",
    "    cv2.rectangle(mtcnn_image, (x_point - 11, y_point - 49), (x2_point + 11, y_point - 24), mtcnn_boxColor, cv2.FILLED)\n",
    "    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "    cv2.putText(mtcnn_image, mtcnn_label, (x_point - 6, y_point - 36), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "rbg_image1 = cv2.cvtColor(mtcnn_image, cv2.COLOR_BGR2RGB)\n",
    "cv2.imshow(\"MTCNN\",rbg_image1)\n",
    "cv2.waitKey(1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DETECT FACE LOCATION USING FACE_RECOGNITION\n",
    "predictionLabel = ''\n",
    "boxColor = (0,0,0)\n",
    "\n",
    "face_recognition_image = face_recognition.load_image_file(image_path)\n",
    "face_recognition_image = cv2.resize(face_recognition_image, (582,448))\n",
    "fr_label=''\n",
    "\n",
    "small_frame = cv2.resize(face_recognition_image, (0, 0), fx=0.25, fy=0.25)\n",
    "rgb_small_frame = small_frame[:, :, ::-1]\n",
    "face_locations = face_recognition.face_locations(rgb_small_frame, model='cnn')\n",
    "\n",
    "print(face_locations)\n",
    "        \n",
    "new_frame = cv2.resize(face_recognition_image, (224,224))\n",
    "x = image.img_to_array(new_frame)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "fr_prediction = mask_no_mask_model.predict(x)\n",
    "\n",
    "if mask_label[np.argmax(fr_prediction, axis=1)[0]] == 'with mask':\n",
    "    fr_label = 'Masked - '\n",
    "    fr_prediction = masked_model.predict(x)\n",
    "    boxColor = (255,0,0)\n",
    "else:\n",
    "    fr_label = 'Unmasked - '\n",
    "    fr_prediction = unmasked_model.predict(x)\n",
    "    boxColor = (0,0,255)\n",
    "\n",
    "fr_label = fr_label + names[np.argmax(fr_prediction, axis=1)[0]]\n",
    "\n",
    "for (top, right, bottom, left) in face_locations:\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "\n",
    "        cv2.rectangle(face_recognition_image, (left - 10, top - 50), (right + 10, bottom + 50), boxColor, 2)\n",
    "        cv2.rectangle(face_recognition_image, (left - 11, top - 49), (right + 11, top -24), boxColor, cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(face_recognition_image, fr_label, (left - 6, top - 36), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "rgb_image2 = cv2.cvtColor(face_recognition_image, cv2.COLOR_BGR2RGB)\n",
    "cv2.imshow('FR', rgb_image2)\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "### VIDEO WITH DNN ###\n",
    "######################\n",
    "predictionLabel = ''\n",
    "boxColor = (0,0,0)\n",
    "\n",
    "network = cv2.dnn.readNetFromCaffe(\"./MODELS/deploy.prototxt\", \"./MODELS/res10_300x300_ssd_iter_140000_fp16.caffemodel\")\n",
    "\n",
    "video = cv2.VideoCapture(0)\n",
    "#video = cv2.VideoCapture(\"../Dataset/Video1.mp4\")\n",
    "\n",
    "\n",
    "if (video.isOpened() == False):\n",
    "    print(\"Web Camera not detected\")\n",
    "while (True):\n",
    "    ret, frame = video.read()\n",
    "    if ret == True:\n",
    "        ### DETECT FACE LOCATION USING DNN\n",
    "        dnn_label = ''\n",
    "        dnn_boxColor = (0,0,0)\n",
    "\n",
    "        dnn_image = cv2.resize(frame, (582,448))\n",
    "\n",
    "        (height, width) = dnn_image.shape[:2]\n",
    "        blob = cv2.dnn.blobFromImage(dnn_image, scalefactor=1.0, size=(300, 300), mean=(104.0, 117.0, 123.0))\n",
    "        network.setInput(blob)\n",
    "        detections = network.forward()\n",
    "        \n",
    "\n",
    "        ###\n",
    "        new_frame = cv2.resize(dnn_image, (224,224))\n",
    "        x = image.img_to_array(new_frame)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        dnn_name_prediction= ''\n",
    "        dnn_mask_prediction = mask_no_mask_model.predict(x)\n",
    "\n",
    "        if mask_label[np.argmax(dnn_mask_prediction, axis=1)[0]] == 'with mask':\n",
    "            dnn_label = 'Masked - '\n",
    "            dnn_name_prediction = masked_model.predict(x)\n",
    "            dnn_boxColor = (255,0,0)\n",
    "        else:\n",
    "            dnn_label = 'Unmasked - '\n",
    "            dnn_name_prediction = unmasked_model.predict(x)\n",
    "            dnn_boxColor = (0,0,255)\n",
    "\n",
    "        dnn_label = dnn_label + names[np.argmax(dnn_name_prediction, axis=1)[0]]\n",
    "        ###\n",
    "\n",
    "        for i in range(0, detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence > 0.7:\n",
    "                box = detections[0, 0, i, 3:7] * np.array([width, height, width, height])\n",
    "                left = int(box[0])\n",
    "                top = int(box[1])\n",
    "                right = int(box[2])\n",
    "                bottom = int(box[3])\n",
    "\n",
    "                cv2.rectangle(dnn_image, (left - 10, top - 50), (right + 10, bottom + 50), dnn_boxColor, 2)\n",
    "                cv2.rectangle(dnn_image, (left - 11, top - 49), (right + 11, top -24), dnn_boxColor, cv2.FILLED)\n",
    "                font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                cv2.putText(dnn_image, dnn_label, (left - 6, top - 36), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "        cv2.imshow(\"DNN\", dnn_image)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "### VIDEO WITH MTCNN ###\n",
    "########################\n",
    "\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "detector = MTCNN()\n",
    "\n",
    "predictionLabel = ''\n",
    "boxColor = (0,0,0)\n",
    "\n",
    "video = cv2.VideoCapture(0)\n",
    "#video = cv2.VideoCapture(\"../Dataset/Video1.mp4\")\n",
    "\n",
    "\n",
    "if (video.isOpened() == False):\n",
    "    print(\"Web Camera not detected\")\n",
    "while (True):\n",
    "    ret, frame = video.read()\n",
    "    if ret == True:\n",
    "        location = detector.detect_faces(frame)\n",
    "        if len(location) > 0:\n",
    "            for face in location:\n",
    "                x_point, y_point, width, height = face['box']\n",
    "                x2_point, y2_point = x_point + width, y_point + height\n",
    "\n",
    "                ###\n",
    "                new_frame = cv2.resize(frame, (224,224))\n",
    "                x = image.img_to_array(new_frame)\n",
    "                x = np.expand_dims(x, axis=0)\n",
    "                x = preprocess_input(x)\n",
    "\n",
    "                prediction = mask_no_mask_model.predict(x)\n",
    "\n",
    "                if mask_label[np.argmax(prediction, axis=1)[0]] == 'with mask':\n",
    "                    predictionLabel = 'Masked - '\n",
    "                    prediction = masked_model.predict(x)\n",
    "                    boxColor = (255,0,0)\n",
    "                else:\n",
    "                    predictionLabel = 'Unmasked - '\n",
    "                    prediction = unmasked_model.predict(x)\n",
    "                    boxColor = (0,0,255)\n",
    "\n",
    "                predictionLabel = predictionLabel + names[np.argmax(prediction, axis=1)[0]]\n",
    "                ###\n",
    "                cv2.rectangle(frame, (x_point - 10, y_point - 50), (x2_point + 10, y2_point + 50), boxColor, 2)\n",
    "                cv2.rectangle(frame, (x_point - 11, y_point - 49), (x2_point + 11, y_point - 24), boxColor, cv2.FILLED)\n",
    "                font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                cv2.putText(frame, predictionLabel, (x_point - 6, y_point - 36), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "        cv2.imshow(\"Output\",frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)\n",
    "#video_capture = cv2.VideoCapture(\"../NEW_DATASET/masked/anudari/IMG_6482.JPG\")\n",
    "\n",
    "# Initialize some variables\n",
    "face_locations = []\n",
    "process_this_frame = True\n",
    "predictionLabel = ''\n",
    "boxColor = (0,0,0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    if process_this_frame:\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "        rgb_small_frame = small_frame[:, :, ::-1]\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        \n",
    "        new_frame = cv2.resize(frame, (224,224))\n",
    "        x = image.img_to_array(new_frame)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        prediction = mask_no_mask_model.predict(x)\n",
    "\n",
    "        if mask_label[np.argmax(prediction, axis=1)[0]] == 'with mask':\n",
    "            predictionLabel = 'Masked - '\n",
    "            prediction = masked_model.predict(x)\n",
    "            boxColor = (255,0,0)\n",
    "        else:\n",
    "            predictionLabel = 'Unmasked - '\n",
    "            prediction = unmasked_model.predict(x)\n",
    "            boxColor = (0,0,255)\n",
    "\n",
    "        predictionLabel = predictionLabel + names[np.argmax(prediction, axis=1)[0]]\n",
    "        ###\n",
    "\n",
    "        \n",
    "\n",
    "    #process_this_frame = not process_this_frame\n",
    "\n",
    "\n",
    "    for (top, right, bottom, left) in face_locations:\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "\n",
    "        cv2.rectangle(frame, (left - 10, top - 50), (right + 10, bottom + 50), boxColor, 2)\n",
    "        cv2.rectangle(frame, (left - 11, top - 49), (right + 11, top -24), boxColor, cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, predictionLabel, (left - 6, top - 36), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tflabs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbd96daefc5ee54ba6257df18db85533615538f8325a5ea7aefbb8022f7048fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
