{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "#grab preprocess from pre-trained model\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image1 = image.load_img(\"./data/Validation_long/female/113241.jpg.jpg\", target_size = (180, 320))\n",
    "image1 = image.load_img(\"../../IN_YOUR_FACE_DATASET/UNMASKED_CELEBRITIES/Will_Smith/Will_Smith_028.jpg\", target_size = (180, 320))\n",
    "\n",
    "\n",
    "transformedImage = image.img_to_array(image1)\n",
    "transformedImage = np.expand_dims(transformedImage, axis = 0)\n",
    "transformedImage = preprocess_input(transformedImage)\n",
    "\n",
    "prediction = model.predict(transformedImage)\n",
    "print(prediction)\n",
    "print(categories[np.argmax(prediction, axis=1)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize some variables\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True\n",
    "predictionLabel = ''\n",
    "\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    if process_this_frame:\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "        rgb_small_frame = small_frame[:, :, ::-1]\n",
    "        \n",
    "        ###\n",
    "        transformedImage = image.img_to_array(rgb_small_frame)\n",
    "        transformedImage = np.expand_dims(transformedImage, axis = 0)\n",
    "        transformedImage = preprocess_input(transformedImage)\n",
    "\n",
    "        # insert final model here\n",
    "        prediction = model.predict(transformedImage)\n",
    "\n",
    "        # insert array of categories here\n",
    "        predictionLabel = categories[np.argmax(prediction, axis=1)[0]]\n",
    "\n",
    "        ###\n",
    "\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "\n",
    "    #process_this_frame = not process_this_frame\n",
    "\n",
    "\n",
    "    for (top, right, bottom, left) in face_locations:\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "\n",
    "        cv2.rectangle(frame, (left - 10, top - 50), (right + 10, bottom + 50), (0, 0, 255), 2)\n",
    "        cv2.rectangle(frame, (left-11, bottom + 50), (right + 11, bottom + 75), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, predictionLabel, (left - 6, bottom + 65), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c2c859e6057e662623fbdd6fb9cb1a717afc58159e33455c5f2d14e3dd744b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
