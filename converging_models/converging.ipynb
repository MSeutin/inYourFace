{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "#grab preprocess from pre-trained model\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.utils import load_img,img_to_array\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras_vggface import utils\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = [\n",
    "#         'Angelina_Jolie', 'Brad_Pitt', 'Denzel_Washington', 'Hugh_Jackman', 'Jennifer_Lawrence', 'Johnny_Depp', \n",
    "#         'Kate_Winslet', 'Leonardo_DiCaprio', 'Megan_Fox', 'Natalie_Portman', 'Nicole_Kidman',\n",
    "#         'Robert_Downey_Jr', 'Sandra_Bullock', 'Scarlett_Johansson', 'Tom_Cruise','Tom_Hanks', 'Will_Smith'\n",
    "#         ]\n",
    "\n",
    "names = [\"Anudari\", \"Cebastian\", \"Chris\", \"Michael\"]\n",
    "\n",
    "mask_label = ['with mask', 'without mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "### MASK/NO MASK ###\n",
    "####################\n",
    "mask_no_mask_model = tf.keras.models.load_model('./MODELS/anudari_mask_nomask_model.h5')\n",
    "#mask_no_mask_model.summary()\n",
    "\n",
    "#####################\n",
    "### UNMASKED FACE ###\n",
    "#####################\n",
    "unmasked_model = tf.keras.models.load_model('./MODELS/new_nomask_model.h5')\n",
    "#unmasked_model.summary()\n",
    "\n",
    "###################\n",
    "### MASKED FACE ###\n",
    "###################\n",
    "masked_model = tf.keras.models.load_model('./MODELS/new_mask_model.h5')\n",
    "#masked_model.summary()\n",
    "\n",
    "######################\n",
    "### LOAD DNN MODEL ###\n",
    "######################\n",
    "network = cv2.dnn.readNetFromCaffe(\"./MODELS/deploy.prototxt\", \"./MODELS/res10_300x300_ssd_iter_140000_fp16.caffemodel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimage1 = image.load_img(\"../NEW_DATASET/masked/chris/IMG_6344.JPG\", target_size = (224, 224))\\n\\ntransformedImage = image.img_to_array(image1)\\ntransformedImage = np.expand_dims(transformedImage, axis = 0)\\ntransformedImage = preprocess_input(transformedImage)\\n\\nprediction = mask_no_mask_model.predict(transformedImage)\\nprint(mask_label[np.argmax(prediction, axis=1)[0]])\\n'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################\n",
    "### MASK/NO MASK ###\n",
    "####################\n",
    "#load the image\n",
    "'''\n",
    "image1 = image.load_img(\"../NEW_DATASET/masked/chris/IMG_6344.JPG\", target_size = (224, 224))\n",
    "\n",
    "transformedImage = image.img_to_array(image1)\n",
    "transformedImage = np.expand_dims(transformedImage, axis = 0)\n",
    "transformedImage = preprocess_input(transformedImage)\n",
    "\n",
    "prediction = mask_no_mask_model.predict(transformedImage)\n",
    "print(mask_label[np.argmax(prediction, axis=1)[0]])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmy_image = load_img('S:/ElitePictures/Home/face.jpeg', target_size=(224, 224))\\n\\n\\n#preprocess the image\\nmy_image = img_to_array(my_image)\\nmy_image = my_image.reshape((1, my_image.shape[0], my_image.shape[1], my_image.shape[2]))\\nmy_image = preprocess_input(my_image)\\n\\n#make the prediction\\nprediction = unmasked_model.predict(my_image)\\nprint(prediction)\\nprint(names[np.argmax(prediction[0])])\\n\""
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################\n",
    "### UNMASKED FACE ###\n",
    "#####################\n",
    "'''\n",
    "my_image = load_img('S:/ElitePictures/Home/face.jpeg', target_size=(224, 224))\n",
    "\n",
    "\n",
    "#preprocess the image\n",
    "my_image = img_to_array(my_image)\n",
    "my_image = my_image.reshape((1, my_image.shape[0], my_image.shape[1], my_image.shape[2]))\n",
    "my_image = preprocess_input(my_image)\n",
    "\n",
    "#make the prediction\n",
    "prediction = unmasked_model.predict(my_image)\n",
    "print(prediction)\n",
    "print(names[np.argmax(prediction[0])])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmy_image = load_img('S:/ElitePictures/Home/face/PXL_20221205_061840469.jpg', target_size=(224, 224))\\n\\n\\n#preprocess the image\\nmy_image = img_to_array(my_image)\\nmy_image = my_image.reshape((1, my_image.shape[0], my_image.shape[1], my_image.shape[2]))\\nmy_image = preprocess_input(my_image)\\n\\n#make the prediction\\nprediction = masked_model.predict(my_image)\\nprint(prediction)\\nprint(names[np.argmax(prediction[0])])\\n\""
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################\n",
    "### MASKED FACE ###\n",
    "###################\n",
    "'''\n",
    "my_image = load_img('S:/ElitePictures/Home/face/PXL_20221205_061840469.jpg', target_size=(224, 224))\n",
    "\n",
    "\n",
    "#preprocess the image\n",
    "my_image = img_to_array(my_image)\n",
    "my_image = my_image.reshape((1, my_image.shape[0], my_image.shape[1], my_image.shape[2]))\n",
    "my_image = preprocess_input(my_image)\n",
    "\n",
    "#make the prediction\n",
    "prediction = masked_model.predict(my_image)\n",
    "print(prediction)\n",
    "print(names[np.argmax(prediction[0])])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmy_image = load_img('../Crop/Cropped_Dataset/masked/Chris/masked_chris_109.jpg', target_size=(224, 224))\\n\\nmy_image = img_to_array(my_image)\\nmy_image = np.expand_dims(my_image, axis=0)\\nmy_image = preprocess_input(my_image)\\n\\npredictionLabel= ''\\nprediction = mask_no_mask_model.predict(my_image)\\n\\nif mask_label[np.argmax(prediction, axis=1)[0]] == 'with mask':\\n    predictionLabel = 'Masked - '\\n    prediction = masked_model.predict(my_image)\\nelse:\\n    predictionLabel = 'Unmasked - '\\n    prediction = unmasked_model.predict(my_image)\\n\\npredictionLabel = predictionLabel + names[np.argmax(prediction, axis=1)[0]]\\n\\n\\nprint(predictionLabel)\\n\""
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################\n",
    "### TEST ONE IMAGE ###\n",
    "######################\n",
    "'''\n",
    "my_image = load_img('../Crop/Cropped_Dataset/masked/Chris/masked_chris_109.jpg', target_size=(224, 224))\n",
    "\n",
    "my_image = img_to_array(my_image)\n",
    "my_image = np.expand_dims(my_image, axis=0)\n",
    "my_image = preprocess_input(my_image)\n",
    "\n",
    "predictionLabel= ''\n",
    "prediction = mask_no_mask_model.predict(my_image)\n",
    "\n",
    "if mask_label[np.argmax(prediction, axis=1)[0]] == 'with mask':\n",
    "    predictionLabel = 'Masked - '\n",
    "    prediction = masked_model.predict(my_image)\n",
    "else:\n",
    "    predictionLabel = 'Unmasked - '\n",
    "    prediction = unmasked_model.predict(my_image)\n",
    "\n",
    "predictionLabel = predictionLabel + names[np.argmax(prediction, axis=1)[0]]\n",
    "\n",
    "\n",
    "print(predictionLabel)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport matplotlib.pyplot as plt\\nimport pandas as pd\\nfrom sklearn.metrics import confusion_matrix\\nimport seaborn as sns\\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\\n\\ntest_data_dir = \\'../NEW_DATASET/mixed/\\'\\ntest_datagen = ImageDataGenerator()\\nTest_data = test_datagen.flow_from_directory(\\n                        test_data_dir,\\n                        batch_size = 1,\\n                        target_size=(224,224),\\n                        shuffle = False) \\n\\n#Predict test images\\nY_pred = mask_no_mask_model.predict(Test_data)\\n\\n#Get corresponding predicted label\\ny_pred = np.argmax(Y_pred, axis=1)\\n\\ncf = confusion_matrix(Test_data.classes, y_pred)\\n\\n\\ndf_cm = pd.DataFrame(cf, index=names, columns=names)\\n\\nsns.heatmap(df_cm, annot= True,fmt=\"d\",cmap=\"YlGnBu\")\\nplt.ylabel(\"Predicted\")\\nplt.xlabel(\"Actual\")\\nplt.title(\"Confusion matrix\\n\")\\nplt.show()\\n'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################################\n",
    "### TEST MULTIPLE MIXED IMAGES ###\n",
    "##################################\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "test_data_dir = '../NEW_DATASET/mixed/'\n",
    "test_datagen = ImageDataGenerator()\n",
    "Test_data = test_datagen.flow_from_directory(\n",
    "                        test_data_dir,\n",
    "                        batch_size = 1,\n",
    "                        target_size=(224,224),\n",
    "                        shuffle = False) \n",
    "\n",
    "#Predict test images\n",
    "Y_pred = mask_no_mask_model.predict(Test_data)\n",
    "\n",
    "#Get corresponding predicted label\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "cf = confusion_matrix(Test_data.classes, y_pred)\n",
    "\n",
    "\n",
    "df_cm = pd.DataFrame(cf, index=names, columns=names)\n",
    "\n",
    "sns.heatmap(df_cm, annot= True,fmt=\"d\",cmap=\"YlGnBu\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.title(\"Confusion matrix\\n\")\n",
    "plt.show()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pandas as pd\\nfrom sklearn.metrics import confusion_matrix\\nimport seaborn as sns\\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\\n\\ntest_data_dir = \\'../Crop/Cropped_Dataset/masked/\\'\\ntest_datagen = ImageDataGenerator(\\n                                 )\\ntest_generator = test_datagen.flow_from_directory(\\n                        test_data_dir,\\n                        target_size=(224,224),\\n                        batch_size=32, \\n                        shuffle = False,\\n                        class_mode=\\'sparse\\') \\n\\n#Confusion Matrix \\nplt.figure(figsize=(15, 5))\\n\\n#Predict test images\\nY_pred = masked_model.predict(test_generator)\\n\\n#Get corresponding predicted label\\ny_pred = np.argmax(Y_pred, axis=1)\\n\\ncf = confusion_matrix(test_generator.classes, y_pred)\\n\\ndf_cm = pd.DataFrame(cf, index=names, columns=names)\\n\\nsns.heatmap(df_cm, annot= True,fmt=\"d\",cmap=\"YlGnBu\")\\nplt.ylabel(\"Predicted\")\\nplt.xlabel(\"Actual\")\\nplt.title(\"Confusion matrix\\n\")\\nplt.show()\\n'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################################\n",
    "### TEST MULTIPLE MIXED IMAGES ###\n",
    "##################################\n",
    "'''\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "test_data_dir = '../Crop/Cropped_Dataset/masked/'\n",
    "test_datagen = ImageDataGenerator(\n",
    "                                 )\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                        test_data_dir,\n",
    "                        target_size=(224,224),\n",
    "                        batch_size=32, \n",
    "                        shuffle = False,\n",
    "                        class_mode='sparse') \n",
    "\n",
    "#Confusion Matrix \n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "#Predict test images\n",
    "Y_pred = masked_model.predict(test_generator)\n",
    "\n",
    "#Get corresponding predicted label\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "cf = confusion_matrix(test_generator.classes, y_pred)\n",
    "\n",
    "df_cm = pd.DataFrame(cf, index=names, columns=names)\n",
    "\n",
    "sns.heatmap(df_cm, annot= True,fmt=\"d\",cmap=\"YlGnBu\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.title(\"Confusion matrix\\n\")\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD IMAGE\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import face_recognition\n",
    "import time\n",
    "\n",
    "image_path = ('../NEW_DATASET/test/presentation/chris_nomask (3).jpg')\n",
    "scale_factor = 0.3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "### VIDEO WITH DNN ###\n",
    "######################\n",
    "predictionLabel = ''\n",
    "boxColor = (0,0,0)\n",
    "\n",
    "network = cv2.dnn.readNetFromCaffe(\"./MODELS/deploy.prototxt\", \"./MODELS/res10_300x300_ssd_iter_140000_fp16.caffemodel\")\n",
    "\n",
    "#video = cv2.VideoCapture(0)\n",
    "video = cv2.VideoCapture(\"../NEW_DATASET/test/IMG_0485.MOV\")\n",
    "\n",
    "\n",
    "\n",
    "if (video.isOpened() == False):\n",
    "    print(\"Web Camera not detected\")\n",
    "while (True):\n",
    "    ret, frame = video.read()\n",
    "    \n",
    "    if ret == True:\n",
    "        frame = cv2.flip(frame, 0)\n",
    "\n",
    "        ### DETECT FACE LOCATION USING DNN\n",
    "        dnn_label = ''\n",
    "        dnn_boxColor = (0,0,0)\n",
    "\n",
    "        dnn_image = cv2.resize(frame, (582,448))\n",
    "\n",
    "        (height, width) = dnn_image.shape[:2]\n",
    "        blob = cv2.dnn.blobFromImage(dnn_image, scalefactor=1.0, size=(300, 300), mean=(104.0, 117.0, 123.0))\n",
    "        network.setInput(blob)\n",
    "        detections = network.forward()\n",
    "        \n",
    "\n",
    "        for i in range(0, detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence > 0.5:\n",
    "                box = detections[0, 0, i, 3:7] * np.array([width, height, width, height])\n",
    "                left = int(box[0])\n",
    "                top = int(box[1])\n",
    "                right = int(box[2])\n",
    "                bottom = int(box[3])\n",
    "\n",
    "                cropped_image = dnn_image[top:bottom, left:right]\n",
    "\n",
    "                if cropped_image.size < 1:\n",
    "                    continue\n",
    "\n",
    "                ###\n",
    "                new_frame = cv2.resize(cropped_image, (224,224))\n",
    "                x = image.img_to_array(new_frame)\n",
    "                x = np.expand_dims(x, axis=0)\n",
    "                x = preprocess_input(x)\n",
    "\n",
    "                dnn_prediction = ''\n",
    "\n",
    "                mask_prediction = mask_no_mask_model.predict(x)\n",
    "\n",
    "                if mask_label[np.argmax(mask_prediction, axis=1)[0]] == 'with mask':\n",
    "                    dnn_label = 'Masked - '\n",
    "                    dnn_prediction = masked_model.predict(x)\n",
    "                    dnn_boxColor = (255,0,0)\n",
    "                else:\n",
    "                    dnn_label = 'Unmasked - '\n",
    "                    dnn_prediction = unmasked_model.predict(x)\n",
    "                    dnn_boxColor = (0,0,255)\n",
    "\n",
    "                dnn_label = dnn_label + names[np.argmax(dnn_prediction, axis=1)[0]]\n",
    "                ###\n",
    "\n",
    "                cv2.rectangle(dnn_image, (left - 10, top - 50), (right + 10, bottom + 50), dnn_boxColor, 2)\n",
    "                cv2.rectangle(dnn_image, (left - 11, top - 49), (right + 11, top -24), dnn_boxColor, cv2.FILLED)\n",
    "                font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                cv2.putText(dnn_image, dnn_label, (left - 6, top - 36), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "        if dnn_image.size < 1:\n",
    "            continue\n",
    "        cv2.imshow(\"DNN\", dnn_image)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "### VIDEO WITH MTCNN ###\n",
    "########################\n",
    "\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "detector = MTCNN()\n",
    "\n",
    "predictionLabel = ''\n",
    "boxColor = (0,0,0)\n",
    "\n",
    "video = cv2.VideoCapture(0)\n",
    "#video = cv2.VideoCapture(\"../Dataset/Video1.mp4\")\n",
    "\n",
    "\n",
    "if (video.isOpened() == False):\n",
    "    print(\"Web Camera not detected\")\n",
    "while (True):\n",
    "    ret, frame = video.read()\n",
    "    if ret == True:\n",
    "        location = detector.detect_faces(frame)\n",
    "        if len(location) > 0:\n",
    "            for face in location:\n",
    "                left, top, width, height = face['box']\n",
    "                right, bottom = left + width, top + height\n",
    "\n",
    "                ###\n",
    "                new_frame = cv2.resize(frame, (224,224))\n",
    "                x = image.img_to_array(new_frame)\n",
    "                x = np.expand_dims(x, axis=0)\n",
    "                x = preprocess_input(x)\n",
    "\n",
    "                prediction = mask_no_mask_model.predict(x)\n",
    "\n",
    "                if mask_label[np.argmax(prediction, axis=1)[0]] == 'with mask':\n",
    "                    predictionLabel = 'Masked - '\n",
    "                    prediction = masked_model.predict(x)\n",
    "                    boxColor = (255,0,0)\n",
    "                else:\n",
    "                    predictionLabel = 'Unmasked - '\n",
    "                    prediction = unmasked_model.predict(x)\n",
    "                    boxColor = (0,0,255)\n",
    "\n",
    "                predictionLabel = predictionLabel + names[np.argmax(prediction, axis=1)[0]]\n",
    "                ###\n",
    "                cv2.rectangle(frame, (left - 10, top - 50), (right + 10, bottom + 50), boxColor, 2)\n",
    "                cv2.rectangle(frame, (left - 11, top - 49), (right + 11, top - 24), boxColor, cv2.FILLED)\n",
    "                font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                cv2.putText(frame, predictionLabel, (left - 6, top - 36), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "        cv2.imshow(\"Output\",frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)\n",
    "#video_capture = cv2.VideoCapture(\"../NEW_DATASET/masked/anudari/IMG_6482.JPG\")\n",
    "\n",
    "# Initialize some variables\n",
    "face_locations = []\n",
    "process_this_frame = True\n",
    "predictionLabel = ''\n",
    "boxColor = (0,0,0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    if process_this_frame:\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "        rgb_small_frame = small_frame[:, :, ::-1]\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        \n",
    "        new_frame = cv2.resize(frame, (224,224))\n",
    "        x = image.img_to_array(new_frame)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        prediction = mask_no_mask_model.predict(x)\n",
    "\n",
    "        if mask_label[np.argmax(prediction, axis=1)[0]] == 'with mask':\n",
    "            predictionLabel = 'Masked - '\n",
    "            prediction = masked_model.predict(x)\n",
    "            boxColor = (255,0,0)\n",
    "        else:\n",
    "            predictionLabel = 'Unmasked - '\n",
    "            prediction = unmasked_model.predict(x)\n",
    "            boxColor = (0,0,255)\n",
    "\n",
    "        predictionLabel = predictionLabel + names[np.argmax(prediction, axis=1)[0]]\n",
    "        ###\n",
    "\n",
    "        \n",
    "\n",
    "    #process_this_frame = not process_this_frame\n",
    "\n",
    "\n",
    "    for (top, right, bottom, left) in face_locations:\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "\n",
    "        cv2.rectangle(frame, (left - 10, top - 50), (right + 10, bottom + 50), boxColor, 2)\n",
    "        cv2.rectangle(frame, (left - 11, top - 49), (right + 11, top -24), boxColor, cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, predictionLabel, (left - 6, top - 36), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tflabs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Oct 13 2022, 21:23:06) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbd96daefc5ee54ba6257df18db85533615538f8325a5ea7aefbb8022f7048fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
