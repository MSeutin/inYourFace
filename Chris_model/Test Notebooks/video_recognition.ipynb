{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import pickle\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "FRAME_THICKNESS = 2\n",
    "FONT_THICKNESS = 1\n",
    "TOLERANCE = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELED_FACES_DIR = \"../Dataset/Training/\"\n",
    "TEST_DIR = \"../Dataset/Testing/\"\n",
    "\n",
    "current_faces = []\n",
    "known_faces = []\n",
    "known_names = []\n",
    "\n",
    "#CREATE ENCODING FOR EACH IMAGE\n",
    "for name in os.listdir(LABELED_FACES_DIR):\n",
    "    for filename in os.listdir(f\"{LABELED_FACES_DIR}/{name}\"):\n",
    "        image = face_recognition.load_image_file(f\"{LABELED_FACES_DIR}/{name}/{filename}\")\n",
    "        encoding = face_recognition.face_encodings(image)[0]\n",
    "        known_faces.append(encoding)\n",
    "        known_names.append(name)\n",
    "\n",
    "#EXPORT ENCODINGS AND LABELS INTO A .DAT FILE\n",
    "with open('known_faces.dat','wb') as f:\n",
    "    pickle.dump(known_faces, f)\n",
    "\n",
    "with open('known_names.dat','wb') as f:\n",
    "    pickle.dump(known_names, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT ENCODINGS AND LABELS OF KNOWN FACES\n",
    "\n",
    "with open('known_faces.dat','rb') as f:\n",
    "    known_faces = pickle.load(f)\n",
    "\n",
    "with open('known_names.dat','rb') as f:\n",
    "    known_names = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNLABELED_FACES_DIR = \"../Dataset/Validation\"\n",
    "\n",
    "\n",
    "#LOOK AT UNKNOWN IMAGES AND CLASSIFY THEM\n",
    "for filename in os.listdir(UNLABELED_FACES_DIR):\n",
    "    print(filename)\n",
    "    image = face_recognition.load_image_file(f\"{UNLABELED_FACES_DIR}/{filename}\")\n",
    "    locations = face_recognition.face_locations(image, model='cnn')\n",
    "    encodings = face_recognition.face_encodings(image, locations)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    for face_encoding, face_location in zip(encodings, locations):\n",
    "        results = face_recognition.compare_faces(known_faces, face_encoding, TOLERANCE)\n",
    "        match = None\n",
    "        if True in results:\n",
    "            match = known_names[results.index(True)]\n",
    "            print(f\"Match found: {match}\")\n",
    "\n",
    "            #A list of tuples of found face locations in css (top, right, bottom, left) order\n",
    "            top_left = (face_location[3]-10, face_location[0]-50)\n",
    "            bottom_right = (face_location[1]+10, face_location[2]+50)\n",
    "            color = [0, 255, 0]\n",
    "            cv2.rectangle(image, top_left, bottom_right, color, FRAME_THICKNESS)\n",
    "\n",
    "            top_left = (face_location[3] - 11, face_location[2] + 50)\n",
    "            bottom_right = (face_location[1] + 11, face_location[2] + 72)\n",
    "            color = [0, 255, 0]\n",
    "            cv2.rectangle(image, top_left, bottom_right, color, cv2.FILLED)\n",
    "\n",
    "            cv2.putText(image, match, (face_location[3], face_location[2]+65), cv2.FONT_HERSHEY_TRIPLEX, 0.5, (0,0,0), FONT_THICKNESS)\n",
    "\n",
    "    cv2.imshow(filename, image)\n",
    "    cv2.waitKey(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing frame 1401 / 2391\n",
      "Writing frame 1402 / 2391\n",
      "Writing frame 1403 / 2391\n",
      "Writing frame 1404 / 2391\n",
      "Writing frame 1405 / 2391\n",
      "Writing frame 1406 / 2391\n",
      "Writing frame 1407 / 2391\n",
      "Writing frame 1408 / 2391\n",
      "Writing frame 1409 / 2391\n",
      "Writing frame 1410 / 2391\n",
      "Writing frame 1411 / 2391\n",
      "Writing frame 1412 / 2391\n",
      "Writing frame 1413 / 2391\n",
      "Writing frame 1414 / 2391\n",
      "Writing frame 1415 / 2391\n",
      "Writing frame 1416 / 2391\n",
      "Writing frame 1417 / 2391\n",
      "Writing frame 1418 / 2391\n",
      "Writing frame 1419 / 2391\n",
      "Writing frame 1420 / 2391\n",
      "Writing frame 1421 / 2391\n",
      "Writing frame 1422 / 2391\n",
      "Writing frame 1423 / 2391\n",
      "Writing frame 1424 / 2391\n",
      "Writing frame 1425 / 2391\n",
      "Writing frame 1426 / 2391\n",
      "Writing frame 1427 / 2391\n",
      "Writing frame 1428 / 2391\n",
      "Writing frame 1429 / 2391\n",
      "Writing frame 1430 / 2391\n",
      "Writing frame 1431 / 2391\n",
      "Writing frame 1432 / 2391\n",
      "Writing frame 1433 / 2391\n",
      "Writing frame 1434 / 2391\n",
      "Writing frame 1435 / 2391\n",
      "Writing frame 1436 / 2391\n",
      "Writing frame 1437 / 2391\n",
      "Writing frame 1438 / 2391\n",
      "Writing frame 1439 / 2391\n",
      "Writing frame 1440 / 2391\n",
      "Writing frame 1441 / 2391\n",
      "Writing frame 1442 / 2391\n",
      "Writing frame 1443 / 2391\n",
      "Writing frame 1444 / 2391\n",
      "Writing frame 1445 / 2391\n",
      "Writing frame 1446 / 2391\n",
      "Writing frame 1447 / 2391\n",
      "Writing frame 1448 / 2391\n",
      "Writing frame 1449 / 2391\n",
      "Writing frame 1450 / 2391\n",
      "Writing frame 1451 / 2391\n",
      "Writing frame 1452 / 2391\n",
      "Writing frame 1453 / 2391\n",
      "Writing frame 1454 / 2391\n",
      "Writing frame 1455 / 2391\n",
      "Writing frame 1456 / 2391\n",
      "Writing frame 1457 / 2391\n",
      "Writing frame 1458 / 2391\n",
      "Writing frame 1459 / 2391\n",
      "Writing frame 1460 / 2391\n",
      "Writing frame 1461 / 2391\n",
      "Writing frame 1462 / 2391\n",
      "Writing frame 1463 / 2391\n",
      "Writing frame 1464 / 2391\n",
      "Writing frame 1465 / 2391\n",
      "Writing frame 1466 / 2391\n",
      "Writing frame 1467 / 2391\n",
      "Writing frame 1468 / 2391\n",
      "Writing frame 1469 / 2391\n",
      "Writing frame 1470 / 2391\n",
      "Writing frame 1471 / 2391\n",
      "Writing frame 1472 / 2391\n",
      "Writing frame 1473 / 2391\n",
      "Writing frame 1474 / 2391\n",
      "Writing frame 1475 / 2391\n",
      "Writing frame 1476 / 2391\n",
      "Writing frame 1477 / 2391\n",
      "Writing frame 1478 / 2391\n",
      "Writing frame 1479 / 2391\n",
      "Writing frame 1480 / 2391\n",
      "Writing frame 1481 / 2391\n",
      "Writing frame 1482 / 2391\n",
      "Writing frame 1483 / 2391\n",
      "Writing frame 1484 / 2391\n",
      "Writing frame 1485 / 2391\n",
      "Writing frame 1486 / 2391\n",
      "Writing frame 1487 / 2391\n",
      "Writing frame 1488 / 2391\n",
      "Writing frame 1489 / 2391\n",
      "Writing frame 1490 / 2391\n",
      "Writing frame 1491 / 2391\n",
      "Writing frame 1492 / 2391\n",
      "Writing frame 1493 / 2391\n",
      "Writing frame 1494 / 2391\n",
      "Writing frame 1495 / 2391\n",
      "Writing frame 1496 / 2391\n",
      "Writing frame 1497 / 2391\n",
      "Writing frame 1498 / 2391\n",
      "Writing frame 1499 / 2391\n"
     ]
    }
   ],
   "source": [
    "input_video = cv2.VideoCapture('../Dataset/Video1.mp4')\n",
    "length = int(input_video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "output_video = cv2.VideoWriter('output.avi', fourcc, 29.97, (640,360))\n",
    "\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "frame_number = 1400\n",
    "\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = input_video.read()\n",
    "    frame_number += 1\n",
    "\n",
    "    # Quit when the input video file ends\n",
    "    if not ret:\n",
    "        break\n",
    "    if frame_number == 1500:\n",
    "        break\n",
    "\n",
    "    # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "    rgb_frame = frame[:, :, ::-1]\n",
    "\n",
    "    locations = face_recognition.face_locations(rgb_frame, model='cnn')\n",
    "    encodings = face_recognition.face_encodings(rgb_frame, locations)\n",
    "\n",
    "    for face_encoding, face_location in zip(encodings, locations):\n",
    "        results = face_recognition.compare_faces(known_faces, face_encoding, TOLERANCE)\n",
    "        match = None\n",
    "        if True in results:\n",
    "            match = known_names[results.index(True)]\n",
    "\n",
    "            #A list of tuples of found face locations in css (top, right, bottom, left) order\n",
    "            top_left = (face_location[3]-10, face_location[0]-50)\n",
    "            bottom_right = (face_location[1]+10, face_location[2]+50)\n",
    "            color = [0, 255, 0]\n",
    "            cv2.rectangle(frame, top_left, bottom_right, color, FRAME_THICKNESS)\n",
    "\n",
    "            top_left = (face_location[3] - 11, face_location[2] + 50)\n",
    "            bottom_right = (face_location[1] + 11, face_location[2] + 72)\n",
    "            color = [0, 255, 0]\n",
    "            cv2.rectangle(frame, top_left, bottom_right, color, cv2.FILLED)\n",
    "\n",
    "            cv2.putText(frame, match, (face_location[3], face_location[2]+65), cv2.FONT_HERSHEY_TRIPLEX, 0.5, (0,0,0), FONT_THICKNESS)\n",
    "\n",
    "    # Write the resulting image to the output video file\n",
    "    print(\"Writing frame {} / {}\".format(frame_number, length))\n",
    "    output_video.write(frame)\n",
    "\n",
    "# All done!\n",
    "input_video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import face_recognition\n",
    "# import cv2\n",
    "\n",
    "# # This is a demo of running face recognition on a video file and saving the results to a new video file.\n",
    "# #\n",
    "# # PLEASE NOTE: This example requires OpenCV (the `cv2` library) to be installed only to read from your webcam.\n",
    "# # OpenCV is *not* required to use the face_recognition library. It's only required if you want to run this\n",
    "# # specific demo. If you have trouble installing it, try any of the other demos that don't require it instead.\n",
    "\n",
    "# # Open the input movie file\n",
    "# input_movie = cv2.VideoCapture(\"hamilton_clip.mp4\")\n",
    "# length = int(input_movie.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# # Create an output movie file (make sure resolution/frame rate matches input video!)\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "# output_movie = cv2.VideoWriter('output.avi', fourcc, 29.97, (640, 360))\n",
    "\n",
    "# # Load some sample pictures and learn how to recognize them.\n",
    "# lmm_image = face_recognition.load_image_file(\"lin-manuel-miranda.png\")\n",
    "# lmm_face_encoding = face_recognition.face_encodings(lmm_image)[0]\n",
    "\n",
    "# al_image = face_recognition.load_image_file(\"alex-lacamoire.png\")\n",
    "# al_face_encoding = face_recognition.face_encodings(al_image)[0]\n",
    "\n",
    "# known_faces = [\n",
    "#     lmm_face_encoding,\n",
    "#     al_face_encoding\n",
    "# ]\n",
    "\n",
    "# # Initialize some variables\n",
    "# face_locations = []\n",
    "# face_encodings = []\n",
    "# face_names = []\n",
    "# frame_number = 0\n",
    "\n",
    "# while True:\n",
    "#     # Grab a single frame of video\n",
    "#     ret, frame = input_movie.read()\n",
    "#     frame_number += 1\n",
    "\n",
    "#     # Quit when the input video file ends\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "#     # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "#     rgb_frame = frame[:, :, ::-1]\n",
    "\n",
    "#     # Find all the faces and face encodings in the current frame of video\n",
    "#     face_locations = face_recognition.face_locations(rgb_frame)\n",
    "#     face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "#     face_names = []\n",
    "#     for face_encoding in face_encodings:\n",
    "#         # See if the face is a match for the known face(s)\n",
    "#         match = face_recognition.compare_faces(known_faces, face_encoding, tolerance=0.50)\n",
    "\n",
    "#         # If you had more than 2 faces, you could make this logic a lot prettier\n",
    "#         # but I kept it simple for the demo\n",
    "#         name = None\n",
    "#         if match[0]:\n",
    "#             name = \"Lin-Manuel Miranda\"\n",
    "#         elif match[1]:\n",
    "#             name = \"Alex Lacamoire\"\n",
    "\n",
    "#         face_names.append(name)\n",
    "\n",
    "#     # Label the results\n",
    "#     for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "#         if not name:\n",
    "#             continue\n",
    "\n",
    "#         # Draw a box around the face\n",
    "#         cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "#         # Draw a label with a name below the face\n",
    "#         cv2.rectangle(frame, (left, bottom - 25), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "#         font = cv2.FONT_HERSHEY_DUPLEX\n",
    "#         cv2.putText(frame, name, (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "#     # Write the resulting image to the output video file\n",
    "#     print(\"Writing frame {} / {}\".format(frame_number, length))\n",
    "#     output_movie.write(frame)\n",
    "\n",
    "# # All done!\n",
    "# input_movie.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tflabs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbd96daefc5ee54ba6257df18db85533615538f8325a5ea7aefbb8022f7048fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
